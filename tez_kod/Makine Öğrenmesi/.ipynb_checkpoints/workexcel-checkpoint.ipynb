{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd385580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import svm\n",
    "satir=0\n",
    "sutun=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c6a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pd.read_excel('input/train1500.xls') # 1500 data in 1887 training data\n",
    "method=CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa1f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=[0,1,2,3,4,5,6,7]\n",
    "z[0]=datas.loc[:,'Gecikti veya Dağıtıma Çıkmadı']\n",
    "z[1]=datas.loc[:,'Evde yok notu düşüldü veya Kapıya Getirilmedi']\n",
    "z[2]=datas.loc[:,'Telefonlara Cevap Verilmedi']\n",
    "z[3]=datas.loc[:,'İade Süreci']\n",
    "z[4]=datas.loc[:,'Teslim Alınmadı veya Teslim Edilmedi']\n",
    "z[5]=datas.loc[:,'Kötü Diyalog Veya Saygısız Tutum']\n",
    "z[6]=datas.loc[:,'Hasarlı veya Kayıp Paket']\n",
    "z[7]=datas.loc[:,'Hijyen Kurallarına Uyulmadı']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a8fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(datas.loc[:,'icerik'],datas.drop(['id','icerik'],axis=1), random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e41f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tks = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "\n",
    "pl = Pipeline([\n",
    "        ('vec', method(token_pattern = tks)),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "pl.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca00d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('input/train1500.xls') # 1500 data in 1887 training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f69130",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(\"\")\n",
    "#predicting\n",
    "train_predictions = pl.predict_proba(train.icerik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e104f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total=[0,0,0,0,0,0,0,0]\n",
    "average=[0,0,0,0,0,0,0,0]\n",
    "for column in range (0,len(z)):\n",
    "    for i in range (0,len(train_predictions)):\n",
    "        total[column]=total[column]+train_predictions[i][column]\n",
    "    average[column]=total[column]/len(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d677f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0 , len(train_predictions)):\n",
    "    for j in range (0,len(z)):\n",
    "        if train_predictions[i][j] < average[j]:\n",
    "            train_predictions[i][j] = 0\n",
    "        else:\n",
    "            train_predictions[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=y_train.columns, index=train.id, data=train_predictions)\n",
    "\n",
    "prediction_df.to_excel('predictions_train_NEW.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846b5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel('input/test387.xls')  # 387 data in 1887 training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252711f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(\"\")\n",
    "#predicting\n",
    "test_predictions = pl.predict_proba(test.icerik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81080d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total=[0,0,0,0,0,0,0,0]\n",
    "average=[0,0,0,0,0,0,0,0]\n",
    "for column in range (0,len(z)):\n",
    "    for i in range (0,len(test_predictions)):\n",
    "        total[column]=total[column]+test_predictions[i][column]\n",
    "    average[column]=total[column]/len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493ebfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0 , len(test_predictions)):\n",
    "    for j in range (0,len(z)):\n",
    "        if test_predictions[i][j] < average[j]:\n",
    "            test_predictions[i][j] = 0\n",
    "        else:\n",
    "            test_predictions[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4229ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=y_test.columns, index=test.id, data=test_predictions)\n",
    "\n",
    "prediction_df.to_excel('predictions_test_NEW.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "8*len(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(train.iloc[satir, sutun+2]) # satır / sütun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9834ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(train_predictions[satir][sutun]) # satır / sütun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b871845",
   "metadata": {},
   "outputs": [],
   "source": [
    "satir=0\n",
    "sutun=0\n",
    "true=0\n",
    "for i in range(len(train_predictions)):\n",
    "    for x in range(8):\n",
    "        sutun=x\n",
    "        print(str(satir)+\",\"+str(sutun))\n",
    "        if int(train.iloc[satir, sutun+2]) == int(train_predictions[satir][sutun]):\n",
    "            print(\"T\")\n",
    "            true=true+1\n",
    "        else:\n",
    "            print(\"F\")\n",
    "    satir=satir+1\n",
    "print(\"In \"+str(len(train_predictions))+\" Train data\")\n",
    "print(\"Totaly:\"+str(8*len(train_predictions))+\" data analyzed\")\n",
    "print(\"Number of true prediction is: \" + str(true))\n",
    "print(\"Number of false prediction is: \" + str(int(8*len(train_predictions)-int(true))))\n",
    "print(\"Accuracy rate:\" + str((true*100)/(8*len(train_predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af6589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "satir=0\n",
    "sutun=0\n",
    "true=0\n",
    "for i in range(len(test_predictions)):\n",
    "    for x in range(8):\n",
    "        sutun=x\n",
    "        print(str(satir)+\",\"+str(sutun))\n",
    "        if int(test.iloc[satir, sutun+2]) == int(train_predictions[satir][sutun]):\n",
    "            print(\"T\")\n",
    "            true=true+1\n",
    "        else:\n",
    "            print(\"F\")\n",
    "    satir=satir+1\n",
    "print(\"In \"+str(len(test_predictions))+\" Test data\")\n",
    "print(\"Totaly:\"+str(8*len(test_predictions))+\" data analyzed\")\n",
    "print(\"Number of true prediction is: \" + str(true))\n",
    "print(\"Number of false prediction is: \" + str(int(8*len(test_predictions)-int(true))))\n",
    "print(\"Accuracy rate:\" + str((true*100)/(8*len(test_predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49e7221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
